# SmolLM2-135M-DPO
Post-training of SmolLM2-135M with Direct Preference Optimization. This is a demo a multilingual alignment of an LLM using samples of the M-RewardBench dataset.
